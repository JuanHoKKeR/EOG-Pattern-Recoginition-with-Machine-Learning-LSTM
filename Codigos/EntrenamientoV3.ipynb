{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.layers import LSTM, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SuperData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions, test_sessions = train_test_split(data['label'].unique(), test_size=0.2, random_state=42)\n",
    "train_data = data[data['label'].isin(train_sessions)]\n",
    "test_data = data[data['label'].isin(test_sessions)]\n",
    "# Normalización\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copia explícita para evitar la advertencia\n",
    "train_data_copy = train_data.copy()\n",
    "test_data_copy = test_data.copy()\n",
    "\n",
    "# Aplicar la transformación a las copias\n",
    "train_data_copy[['horizontal', 'vertical']] = scaler.fit_transform(train_data_copy[['horizontal', 'vertical']])\n",
    "test_data_copy[['horizontal', 'vertical']] = scaler.transform(test_data_copy[['horizontal', 'vertical']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for label, group in train_data.groupby('label'):\n",
    "    seq = group[['horizontal', 'vertical']].values\n",
    "    X_train.append(seq)\n",
    "\n",
    "for label, group in train_data.groupby('label'):\n",
    "    if 'R' in group['movement_type'].values:\n",
    "        y_train.append(2)\n",
    "    elif 'L' in group['movement_type'].values:\n",
    "        y_train.append(1)\n",
    "    elif 'U' in group['movement_type'].values:\n",
    "        y_train.append(3)\n",
    "    elif 'D' in group['movement_type'].values:\n",
    "        y_train.append(4)\n",
    "    else:\n",
    "        y_train.append(0)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for label, group in test_data.groupby('label'):\n",
    "    seq = group[['horizontal', 'vertical']].values\n",
    "    X_test.append(seq)\n",
    "\n",
    "for label, group in test_data.groupby('label'):\n",
    "    if 'R' in group['movement_type'].values:\n",
    "        y_test.append(2)\n",
    "    elif 'L' in group['movement_type'].values:\n",
    "        y_test.append(1)\n",
    "    elif 'U' in group['movement_type'].values:\n",
    "        y_test.append(3)\n",
    "    elif 'D' in group['movement_type'].values:\n",
    "        y_test.append(4)\n",
    "    else:\n",
    "        y_test.append(0)\n",
    "\n",
    "# Convert X_train, y_train, X_test, and y_test to numpy arrays\n",
    "X_train = np.array(X_train, dtype=object)\n",
    "# Convert labels to one-hot vectors\n",
    "y_train = to_categorical(y_train, num_classes=5)\n",
    "\n",
    "X_test = np.array(X_test, dtype=object)\n",
    "y_test = to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Asus\\Documents\\aUniversidad\\SEMESTRE 23-2\\Bio_I\\Proyecto\\venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Asus\\Documents\\aUniversidad\\SEMESTRE 23-2\\Bio_I\\Proyecto\\venv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\Asus\\Documents\\aUniversidad\\SEMESTRE 23-2\\Bio_I\\Proyecto\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Asus\\Documents\\aUniversidad\\SEMESTRE 23-2\\Bio_I\\Proyecto\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6872 - accuracy: 0.2143  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 512s 99s/step - loss: 1.6872 - accuracy: 0.2143\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6073 - accuracy: 0.3010  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 475s 110s/step - loss: 1.6073 - accuracy: 0.3010\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5922 - accuracy: 0.3469  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 451s 101s/step - loss: 1.5922 - accuracy: 0.3469\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5672 - accuracy: 0.3622  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 452s 102s/step - loss: 1.5672 - accuracy: 0.3622\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5194 - accuracy: 0.3878  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 456s 102s/step - loss: 1.5194 - accuracy: 0.3878\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4541 - accuracy: 0.4490  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 588s 109s/step - loss: 1.4541 - accuracy: 0.4490\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3819 - accuracy: 0.4490  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 450s 101s/step - loss: 1.3819 - accuracy: 0.4490\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3531 - accuracy: 0.4133  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 451s 100s/step - loss: 1.3531 - accuracy: 0.4133\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3179 - accuracy: 0.4847  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 441s 98s/step - loss: 1.3179 - accuracy: 0.4847\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2987 - accuracy: 0.4745  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 448s 100s/step - loss: 1.2987 - accuracy: 0.4745\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4909 - accuracy: 0.4082  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 452s 101s/step - loss: 1.4909 - accuracy: 0.4082\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2581 - accuracy: 0.4286  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 454s 101s/step - loss: 1.2581 - accuracy: 0.4286\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3147 - accuracy: 0.3980  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 1333s 394s/step - loss: 1.3147 - accuracy: 0.3980\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2434 - accuracy: 0.4643  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 491s 101s/step - loss: 1.2434 - accuracy: 0.4643\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2693 - accuracy: 0.4949  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 454s 101s/step - loss: 1.2693 - accuracy: 0.4949\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2332 - accuracy: 0.5000  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 455s 101s/step - loss: 1.2332 - accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.3020 - accuracy: 0.4898  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 446s 99s/step - loss: 1.3020 - accuracy: 0.4898\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2246 - accuracy: 0.5153  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 458s 103s/step - loss: 1.2246 - accuracy: 0.5153\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2648 - accuracy: 0.5408  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 454s 101s/step - loss: 1.2648 - accuracy: 0.5408\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2232 - accuracy: 0.5459  WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "4/4 [==============================] - 672s 173s/step - loss: 1.2232 - accuracy: 0.5459\n",
      "2/2 [==============================] - 4s 588ms/step - loss: 1.4026 - accuracy: 0.4082\n",
      "Test Accuracy: 40.82%\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "# Define your model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True, kernel_regularizer=regularizers.l2(0.01)))  # L2 regularization\n",
    "model.add(Dropout(0.5))  # Dropout\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile your model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "X_train_padded = pad_sequences(X_train, dtype='float32', padding='post')\n",
    "X_test_padded = pad_sequences(X_test, dtype='float32', padding='post')\n",
    "\n",
    "# Now, you can feed the padded sequences into your model\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(X_train_padded, y_train, epochs=20, batch_size=64, callbacks=[early_stop])\n",
    "\n",
    "# Evaluate your model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\aUniversidad\\SEMESTRE 23-2\\Bio_I\\Proyecto\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('my_modelV5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\aUniversidad\\SEMESTRE 23-2\\Bio_I\\Proyecto\\venv\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 200ms/step\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# Load the new dataset\n",
    "probe_data = pd.read_csv('prueba5.csv')\n",
    "\n",
    "# Preprocess the probe data in the same way as your training data\n",
    "X_probe = []\n",
    "for label, group in probe_data.groupby('label'):\n",
    "    seq = group[['horizontal', 'vertical']].values\n",
    "    seq = scaler.transform(seq)  # Normalize the data\n",
    "    X_probe.append(seq)\n",
    "X_probe = pad_sequences(X_probe, dtype='float32', padding='post')\n",
    "\n",
    "# Use the model to predict the class labels for the probe data\n",
    "y_probe_pred = model.predict(X_probe)\n",
    "\n",
    "# The output, y_probe_pred, is a 2D array with the probabilities for each class.\n",
    "# To get the predicted class labels, you can use argmax to find the class with the highest probability.\n",
    "y_probe_pred_labels = np.argmax(y_probe_pred, axis=1)\n",
    "print(y_probe_pred_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
